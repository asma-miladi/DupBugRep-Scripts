{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled8.ipynb","provenance":[],"authorship_tag":"ABX9TyMf5Fty6HPjLrB+BMHXzNDD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_rzBFyXVVZwv"},"source":["#Importing packages\r\n","#import nltk\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","import re\r\n","import string\r\n","#from nltk import sent_tokenize, word_tokenize\r\n","#from nltk.corpus import stopwords\r\n","from nltk.stem.porter import PorterStemmer\r\n","import numpy as np\r\n","from tensorflow.keras import optimizers\r\n","from tensorflow.python.keras.optimizers import TFOptimizer\r\n","import numpy as np\r\n","from nltk.corpus import stopwords\r\n","import string\r\n","from pickle import load\r\n","from numpy import array\r\n","from keras.preprocessing.text import Tokenizer\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.utils.vis_utils import plot_model\r\n","from keras.models import Model\r\n","from keras.layers import Input\r\n","from keras.layers import Dense\r\n","from keras.layers import Flatten\r\n","from keras.layers import Dropout\r\n","from keras.layers import Embedding\r\n","from keras.layers.convolutional import Conv1D\r\n","from keras.layers.convolutional import Conv2D\r\n","from keras.layers.convolutional import Conv3D\r\n","from keras.layers.convolutional import MaxPooling2D\r\n","from keras.layers.convolutional import MaxPooling3D\r\n","from keras.layers.convolutional import MaxPooling1D\r\n","from keras.layers.normalization import BatchNormalization\r\n","from keras.layers.merge import concatenate\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","\r\n","def clean_doc(doc):\r\n","\ttokens = doc.split()\r\n","\ttable = str.maketrans('', '', string.punctuation)\r\n","\t#nltk.max_length=300\r\n","\ttokens = [w.translate(table) for w in tokens]\r\n","\ttokens = [word for word in tokens if word.isalpha()]\r\n","\tstop_words = list(set(stopwords.words('english')))\r\n","\tnewStopWords = ['java','com','org']\r\n","\tstop_words.extend(newStopWords)\r\n","\ttokens = [w for w in tokens if not w in stop_words]\r\n","\ttokens = [word for word in tokens if len(word) > 1]\r\n","\tps = PorterStemmer()\r\n","\ttokens=[ps.stem(word) for word in tokens]\r\n","\t#max_length(tokens)\r\n","\treturn tokens\r\n","\r\n","\r\n","def get_all_elements_in_list_of_lists(list):\r\n","    count = 0\r\n","    for element in list:\r\n","        count += len(element)\r\n","    return count\r\n","\r\n","import nltk\r\n","nltk.download('stopwords')\r\n","\r\n","import re\r\n","from gensim.models import Phrases\r\n","from gensim.models import Word2Vec\r\n","import gensim\r\n","import csv\r\n","labeldup=[]\r\n","################################################ TRAINDATA\r\n","\r\n","with open(\"train_dup_ec1.csv\", \"r\") as f, open(\"train_dup_ec2.csv\", \"r\") as f1, open(\"train_nn_dup_ec1.csv\", \"r\") as fnd1, open(\"train_nn_dup_ec2.csv\", \"r\") as fnd2:     \r\n","        reader = csv.reader(f)\r\n","        reader1 = csv.reader(f1)\r\n","        reader2 = csv.reader(fnd1)\r\n","        reader3 = csv.reader(fnd2)\r\n","\r\n","        rownumber = 0    \r\n","\r\n","        traindata = []\r\n","\r\n","        \r\n","        for row, row1, row2, row3 in zip(reader, reader1, reader2, reader3):\r\n","\r\n","             for c in row :\r\n","\r\n","                 cleanrow= clean_doc(c)\r\n","             traindata.append(cleanrow)\r\n","\r\n","             for c1 in row1 :\r\n","                 cleanrow1= clean_doc(c1)    \r\n","             traindata.append(cleanrow1)\r\n","             \r\n","             for c2 in row2 :\r\n","                 cleanrow2= clean_doc(c2)            \r\n","             traindata.append(cleanrow2)\r\n","\r\n","             for c3 in row3 :\r\n","                 cleanrow3= clean_doc(c3)            \r\n","             traindata.append(cleanrow3)         \r\n","             \r\n","    \r\n"," \r\n","        model = gensim.models.Word2Vec(traindata, size=20, min_count=1,  sg=0) \r\n","\r\n","\r\n","with open(\"train_dup_ec1.csv\", \"r\") as f, open(\"train_dup_ec2.csv\", \"r\") as f1, open(\"train_nn_dup_ec1.csv\", \"r\") as fnd1, open(\"train_nn_dup_ec2.csv\", \"r\") as fnd2:     \r\n","        reader = csv.reader(f)\r\n","        reader1 = csv.reader(f1)\r\n","        reader2 = csv.reader(fnd1)\r\n","        reader3 = csv.reader(fnd2)\r\n","\r\n","        rownumber = 0    \r\n","        pair_d=[]\r\n","        pair_nd=[]\r\n","        train=[]\r\n","        matrix_b1=[]\r\n","        matrix_b2=[]\r\n","        matrix_b3=[]\r\n","        matrix_b4=[]\r\n","\r\n","        traindata = []\r\n","        train_d1=[]\r\n","        train_d2=[]\r\n","        train_nd1=[]\r\n","        train_nd2=[]        \r\n","        len_token=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\r\n","        #f = open(\"follow2.txt\", 'w')     \r\n","        #Cleaning\r\n","        for row, row1, row2, row3 in zip(reader, reader1, reader2, reader3):\r\n","             \r\n","             for c in row :\r\n","                 cleanrow= clean_doc(c)\r\n","                 #print(cleanrow)\r\n","             for c1 in row1 :\r\n","                 cleanrow1= clean_doc(c1) \r\n","             for c2 in row2 :\r\n","                 cleanrow2= clean_doc(c2)            \r\n","             for c3 in row3 :\r\n","                 cleanrow3= clean_doc(c3)  \r\n","                 \r\n","################################## Duplicate Bug report 1\r\n","\r\n","             \r\n","             #f.write(\"Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                \r\n","                \r\n","             #f.write(str(cleanrow))\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","             \r\n","             \r\n","             matrix_b1=[] \r\n","             \r\n","             matrix_b1= list(matrix_b1)        \r\n","             for i in cleanrow :        \r\n","                 \r\n","                     matrix1_b= model.wv[i] \r\n","                     \r\n","                     matrix_b1.append(matrix1_b)\r\n","                     \r\n","                     \r\n","                     \r\n","                     \r\n","             #f.write(\"matrix_b1:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b1))\r\n","             \r\n","             #f.write(\"\\n\")\r\n","                 \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b1:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b1)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","             \r\n","             \r\n","             \r\n","###############################################################\r\n","             \r\n","     #Duplicate Bug report 2      \r\n","             #f.write(\"Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(cleanrow1))\r\n","             #f.write(\"\\n\")             \r\n","\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")                     \r\n","                     \r\n","             matrix_b2=[]         \r\n","             matrix_b2= list(matrix_b2)        \r\n","             for i in cleanrow1 :        \r\n","                 \r\n","                     matrix2_b= model.wv[i]                     \r\n","                     matrix_b2.append(matrix2_b)  \r\n","                     \r\n","             #f.write(\"matrix_b2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b2))\r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #print(matrix_b1)   \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b2)))  \r\n","             \r\n","             \r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b1)):\r\n","                 matrix_b1.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b2)):\r\n","                 matrix_b2.append(len_token)\r\n","             \r\n","            \r\n","\r\n","\r\n","\r\n","\r\n","             train_d1.append(matrix_b1)\r\n","             train_d2.append(matrix_b2)\r\n","       \r\n","                    \r\n","             rownumber = rownumber + 1\r\n","             print(\"train\",rownumber)\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(str(matrix_b2))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(train_d2))\r\n","             #f.write(\"\\n\")\r\n","\r\n","####################################################################################\r\n","             \r\n"," #Non Duplicate pairs \r\n","             \r\n","             \r\n","             #f.write(\"Non Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                          \r\n","             #f.write(str(cleanrow2))\r\n","             #f.write(\"\\n\")             \r\n","             \r\n","             \r\n","             matrix_b3=[] \r\n","             matrix_b3= list(matrix_b3)\r\n","             for i in cleanrow2 :\r\n","\r\n","                     matrix1_nb= model.wv[i]                        \r\n","                     matrix_b3.append(matrix1_nb)\r\n","                     \r\n","             #f.write(\"matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b3))\r\n","             \r\n","             #f.write(\"\\n\")\r\n"," \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b3)))\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n"," \r\n","##################################################################\"\"\"\"\r\n","\r\n","                    \r\n","        # Non Duplicate Bug report 2 \r\n","\r\n","             #f.write(\"Non Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")   \r\n","             \r\n","             #f.write(str(cleanrow3))\r\n","             #f.write(\"\\n\")\r\n","                 \r\n","             matrix_b4=[]         \r\n","             matrix_b4= list(matrix_b4)      \r\n","             \r\n","             \r\n","             \r\n","             for i in cleanrow3 :        \r\n","                 \r\n","                     matrix2_nb= model.wv[i]                     \r\n","                     matrix_b4.append(matrix2_nb) \r\n","                     \r\n","                     \r\n","             for i in range(300 - len(matrix_b3)):\r\n","                 matrix_b3.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b4)):\r\n","                 matrix_b4.append(len_token)\r\n","             \r\n","                \r\n","\r\n","             train_nd1.append(matrix_b3)\r\n","             train_nd2.append(matrix_b4)             \r\n","                \r\n","                \r\n","                \r\n","             #f.write(\"matrix_b4\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b4))\r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #print(matrix_b1) \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b4\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b4)))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(train_nd2))\r\n","             #f.write(\"\\n\")\r\n","\r\n","             \r\n","             rownumber = rownumber + 1\r\n","             print(\"train\",rownumber)\r\n","        #f.close()  \r\n","\r\n","train_1 = train_d1 + train_nd1 #br1\r\n","train_2 = train_d2 + train_nd2  #br2\r\n","\r\n","################################################### TEST \"\"\"\"\"\"\r\n","\r\n","\r\n","with open(\"test_dup_ec1.csv\", \"r\") as f, open(\"test_dup_ec2.csv\", \"r\") as f1, open(\"test_nn_dup_ec1.csv\", \"r\") as fnd1, open(\"test_nn_dup_ec2.csv\", \"r\") as fnd2:     \r\n","        reader = csv.reader(f)\r\n","        reader1 = csv.reader(f1)\r\n","        reader2 = csv.reader(fnd1)\r\n","        reader3 = csv.reader(fnd2)\r\n","        rownumber = 0    \r\n","        test_d=[]\r\n","        b1=[]\r\n","        test_nd=[]\r\n","        b2=[]\r\n","        test=[]\r\n","        matrix_b1=[]\r\n","        matrix_b2=[]\r\n","        matrix_b3=[]\r\n","        matrix_b4=[]\r\n","        test_d1=[]\r\n","        test_d2=[]\r\n","        test_nd1=[]\r\n","        test_nd2=[]         \r\n","      \r\n","        traindata = []\r\n","        non_vocab= [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\r\n","        MAX_SEQUENCE_LENGTH =300\r\n","        #f = open(\"t2.txt\", 'w')\r\n","        for row, row1, row2, row3 in zip(reader, reader1, reader2, reader3):\r\n","             #g=open('dup_mat/'\"train\"+str(rownumber)+\".txt\",\"w\")\r\n","             for c in row :\r\n","                 cleanrow= clean_doc(c)\r\n","             for c1 in row1 :\r\n","                 cleanrow1= clean_doc(c1) \r\n","             for c2 in row2 :\r\n","                 cleanrow2= clean_doc(c2)            \r\n","             for c3 in row3 :\r\n","                 cleanrow3= clean_doc(c3)   \r\n"," \r\n","             #f.write(\"Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                   \r\n","                 \r\n","             #f.write(str(cleanrow))\r\n","             #f.write(\"\\n\")                  \r\n","\r\n","             #f.write(\"\\n\")\r\n","             matrix_b1=[]    \r\n","             matrix_b1= list(matrix_b1)    \r\n","             for i in cleanrow :\r\n","                 if i in model.wv.vocab:\r\n","                     matrix1_b= model.wv[i]                         \r\n","                     matrix_b1.append(matrix1_b) \r\n","                     \r\n","                 else:\r\n","                     matrix_b1.append(non_vocab) \r\n","                  \r\n","                     \r\n","             #f.write(\"matrix_b1:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b1))\r\n","                 \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b1:\")\r\n","             #f.write(str(len(matrix_b1)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","             \r\n","##########################################â™£\"\"             \r\n","             \r\n","#Duplicate Bug report 2 \r\n","             \r\n","\r\n","             #f.write(\" Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")   \r\n","\r\n","             #f.write(str(cleanrow1))\r\n","             #f.write(\"\\n\")              \r\n","\r\n","             #f.write(\"\\n\")                     \r\n","             \r\n","             \r\n","             \r\n","             \r\n","             matrix_b2=[]    \r\n","             matrix_b2= list(matrix_b2)        \r\n","             for i in cleanrow1 :\r\n","                 if i in model.wv.vocab:\r\n","                     #print(i)                    \r\n","                     matrix2_b= model.wv[i]                     \r\n","                     matrix_b2.append(matrix2_b) \r\n","                 else:\r\n","                     matrix_b2.append(non_vocab) \r\n"," \r\n","             #f.write(\"matrix_b2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b2))\r\n","  \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b1:\")\r\n","             #f.write(str(len(matrix_b2)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","\r\n","\r\n","\r\n","             for i in range(300 - len(matrix_b1)):\r\n","                 matrix_b1.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b2)):\r\n","                 matrix_b2.append(len_token)\r\n","             \r\n","\r\n","\r\n","             test_d1.append(matrix_b1)\r\n","             test_d2.append(matrix_b2)    \r\n","             \r\n","             #f.write(\"\\n\")\r\n","            # f.write(\"test_d:\") \r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(test_d))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")             \r\n","             \r\n","             \r\n","             \r\n","             \r\n","             #print(test_d)\r\n","             \r\n","             #f.write(\"Non Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                \r\n","             \r\n","             #f.write(str(cleanrow2))\r\n","\r\n","             #f.write(\"\\n\")\r\n","\r\n","             \r\n","             matrix_b3=[]    \r\n","             matrix_b3= list(matrix_b3)\r\n","             for i in cleanrow2 :\r\n","                 if i in model.wv.vocab:\r\n","                     matrix1_nb= model.wv[i]                        \r\n","                     matrix_b3.append(matrix1_nb)\r\n","                 else:\r\n","                     matrix_b3.append(non_vocab)\r\n","\r\n","             #f.write(\"matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b3))\r\n","  \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b3)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","\r\n","                  \r\n","    #Duplicate Bug report 2    \r\n","\r\n","\r\n","             #f.write(\"Non Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")   \r\n","\r\n","\r\n","\r\n","             #f.write(str(cleanrow3))\r\n","             #f.write(\"\\n\") \r\n","\r\n","             #f.write(\"\\n\")\r\n","              \r\n","             matrix_b4=[]    \r\n","             matrix_b4= list(matrix_b4)        \r\n","             for i in cleanrow3 :\r\n","                 if i in model.wv.vocab:\r\n","                     #print(i)                    \r\n","                     matrix2_nb= model.wv[i]                     \r\n","                     matrix_b4.append(matrix2_nb) \r\n","                 else:\r\n","                     matrix_b4.append(non_vocab)\r\n","\r\n","             #f.write(\"matrix_b4:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b4))\r\n","  \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b4:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b4)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","             \r\n","             for i in range(300 - len(matrix_b3)):\r\n","                 matrix_b3.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b4)):\r\n","                 matrix_b4.append(len_token)\r\n","             \r\n","                \r\n","             #print(matrix_b2)   \r\n","\r\n","             test_nd1.append(matrix_b3)\r\n","             test_nd2.append(matrix_b4)    \r\n","             #print(pairx)\r\n","\r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"test_nd:\") \r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(test_nd))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")             \r\n","                          \r\n","             rownumber = rownumber + 1\r\n","             #f.close()         \r\n","             \r\n","test_1 = test_d1 + test_nd1\r\n","test_2 = test_d2 + test_nd2\r\n","      \r\n","\r\n","#train= np.stack([train_1,train_2],axis=0)\r\n","#test= np.stack([test_1,test_2],axis=0)\r\n","#m =np.stack([2,4],axis=-1)\r\n","#print(train.shape)\r\n","#print(test.shape)\r\n","#train_1 =np.array(train_1)\r\n","#train_2 =np.array(train_2)\r\n","#test_1 =np.array(test_1)\r\n","#test2=np.array(test_2)\r\n","\r\n","\r\n","\"\"\"\r\n","mat = np.empty((len(a),len(b)),dtype='object')\r\n","for i,aa in enumerate(a):\r\n","    for j,bb in enumerate(b): \r\n","        mat[i,j] = np.array([aa,bb],dtype='object')\r\n","\"\"\"\r\n","\r\n","#train_1  : train duplicate + train non dup : BR1\r\n","#train_2   :train  dup + train non dup : BR2 \r\n","\r\n","\r\n","train_1=np.array(train_1)\r\n","train_2=np.array(train_2)\r\n","test_1=np.array(test_2)\r\n","test_2=np.array(test_1)\r\n","print(train_1.shape)\r\n","print(test_1.shape)\r\n","\r\n","\"\"\"\r\n","train_1.resize((300,20),refcheck = False) \r\n","train_2.resize((300,20),refcheck = False) \r\n","train= np.stack([train_1, train_2], axis=-1)\r\n","\r\n","test_1.resize((300,20),refcheck = False) \r\n","test_2.resize((300,20),refcheck = False) \r\n","test= np.stack([test_1, test_2], axis=-1)\r\n","\"\"\"\r\n","\r\n","import tensorflow as tf\r\n","tf.keras.metrics.Precision( thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\r\n","tf.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\r\n","tf.keras.metrics.FalseNegatives( thresholds=None, name=None, dtype=None)\r\n","tf.keras.metrics.FalsePositives(thresholds=None, name=None, dtype=None)\r\n","tf.keras.metrics.TrueNegatives(thresholds=None, name=None, dtype=None)\r\n","tf.keras.metrics.TruePositives(thresholds=None, name=None, dtype=None)\r\n","#tf.keras.metrics.Accuracy(name='accuracy', dtype=None)\r\n","#tf.keras.metrics.Accuracy(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\r\n","import tensorflow as tf\r\n","import tensorflow \r\n","from keras import layers\r\n","from keras import Input\r\n","from tensorflow import keras\r\n","from keras.layers import Dense\r\n","from tensorflow.keras.layers import Reshape\r\n","# define the model\r\n","\r\n","import keras.backend as k\r\n","\r\n","\r\n","train_1=np.asarray(train_1)\r\n","train_2=np.asarray(train_2)\r\n","test_1=np.asarray(test_1)\r\n","test_2=np.asarray(test_2)\r\n","\r\n","#import tf.keras.layers.Reshape\r\n","def define_model():\r\n","\t# channel 1\r\n","    #inputs1 = Input(shape=(tt.shape)) \r\n","    inputs1 = Input(shape=(300,20)) \r\n","    inputs2 = Input(shape=(300,20)) \r\n","    inputs12=tf.keras.backend.stack(([inputs1,inputs2]),axis=-1) #(300,20,2) tf.keras.backend.stack(     x,     axis=0 ) \r\n","    #inputs12 = concatenate([inputs1, inputs2])\r\n","    print(\"inputs1: \",inputs1.shape)\r\n","    conv1 = Conv2D(filters=100, kernel_size=(1,20), padding='valid', activation='relu', data_format='channels_last')(inputs12)\r\n","    #print(conv1)# \"(300,1,100)\"\r\n","    print(\"conv1:\",conv1.shape)\r\n","    x= layers.Reshape((300,100,1))(conv1)\r\n","    print(\"x:\",x.shape)\r\n","    conv11 = Conv2D(filters=200, kernel_size=(1,100), padding='valid', activation='relu')(x)\r\n","    print(\"conv11:\",conv11.shape)\r\n","    pool11 = MaxPooling2D(pool_size=(300, 1))(conv11)\r\n","    print(\"pool11:\",pool11.shape)\r\n","    flat11 = Flatten()(pool11)\r\n","    print(flat11.shape)\r\n","    # Branch12\r\n","    conv12 = Conv2D(filters=200, kernel_size=(2,100), padding='valid', activation='relu')(x)\r\n","    print(\"conv12:\",conv12.shape)\r\n","    pool12 = MaxPooling2D(pool_size=(299, 1))(conv12)\r\n","    print(\"pool12:\",pool12.shape)\r\n","    flat12 = Flatten()(pool12)\r\n","    # Branch13\r\n","    conv13 = Conv2D(filters=200, kernel_size=(3,100), padding='valid', activation='relu')(x)\r\n","    print(\"conv13:\",conv13.shape)\r\n","    pool13 = MaxPooling2D(pool_size=(298, 1))(conv13)\r\n","    print(\"pool13:\", pool13.shape)\r\n","    flat13 = Flatten()(pool13)\r\n","    # Branch21\r\n","    conv2 = Conv2D(filters=100, kernel_size=(2,20), padding='valid', activation='relu', data_format='channels_last')(inputs12)\r\n","    print(\"conv2: \", conv2.shape )\r\n","    x2 = layers.Reshape((299,100,1))(conv2)\r\n","    print(\"x2:\", x2.shape)\r\n","    conv21 = Conv2D(filters=200, kernel_size=(1,100), padding='valid', activation='relu')(x2)\r\n","    print(\"conv21 :\",conv21.shape)\r\n","    pool21 = MaxPooling2D(pool_size=(299, 1))(conv21)#o2-maxpooling\r\n","    print(\"pool21: \",pool21.shape)\r\n","    flat21 = Flatten()(pool21)\r\n","    #Branch22\r\n","    conv22 = Conv2D(filters=200, kernel_size=(2,100), padding='valid', activation='relu')(x2)\r\n","    print(\"conv22:\", conv22.shape)\r\n","    pool22 = MaxPooling2D(pool_size=(298, 1))(conv22)\r\n","    print(\"pool22:\",pool22.shape)\r\n","    flat22 = Flatten()(pool22)\r\n","    #Branch23\r\n","    conv23 = Conv2D(filters=200, kernel_size=(3,100), padding='valid', activation='relu')(x2)\r\n","    print(\"conv23:\",conv23.shape)\r\n","    pool23 = MaxPooling2D(pool_size=(297, 1))(conv23)\r\n","    print(\"pool23: \",pool23.shape)\r\n","    flat23 = Flatten()(pool23)\r\n","    #Branch31\r\n","    conv3 = Conv2D(filters=100, kernel_size=(3,20), padding='valid', activation='relu', data_format='channels_last')(inputs12)\r\n","    print(\"conv3\",conv3.shape)\r\n","    x3 = layers.Reshape((298,100,1))(conv3)\r\n","    print(\"x3\",x3.shape)\r\n","    conv31 = Conv2D(filters=200, kernel_size=(1,100), padding='valid', activation='relu')(x3)\r\n","    print(\"conv31: \",conv31.shape)\r\n","    pool31 = MaxPooling2D(pool_size=(298, 1))(conv31)\r\n","    print(\"pool31\",pool31.shape)\r\n","    flat31 = Flatten()(pool31)\r\n","    #Branch32\r\n","    conv32 = Conv2D(filters=200, kernel_size=(2,100), padding='valid', activation='relu')(x3)\r\n","    print(\"conv32: \",conv32.shape)\r\n","    pool32 = MaxPooling2D(pool_size=(297, 1))(conv32)\r\n","    print(\"pool32\",pool32.shape)\r\n","    flat32 = Flatten()(pool32)\r\n","    #Branch33\r\n","    conv33 = Conv2D(filters=200, kernel_size=(3,100), padding='valid', activation='relu')(x3)\r\n","    print(\"conv33: \",conv33.shape)\r\n","    pool33 = MaxPooling2D(pool_size=(296, 1))(conv33)\r\n","    print(\"pool33\",pool33.shape)\r\n","    flat33 = Flatten()(pool33)\r\n","    # merge 'May be merge pools then flatten\r\n","    merged = concatenate([flat11, flat12, flat13, flat21, flat22, flat23, flat31, flat32, flat33])\r\n","    print(\"merged: \",merged.shape)\r\n","    # interpretation\r\n","    dense1 = Dense(300, activation='relu')(merged)\r\n","    dense2 = Dense(100, activation='relu')(dense1)\r\n","    outputs = Dense(1, activation='sigmoid')(dense2)\r\n","    print(outputs.shape)\r\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs) #think about this\r\n","    # compile\r\n","    model.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy'])\r\n","    #model.compile(optimizer='adam', loss='binary_crossentropy' , metrics=[tf.keras.metrics.Accuracy(),tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.FalseNegatives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(), tf.keras.metrics.TruePositives() ])\r\n","\r\n","    # summarize\r\n","    print(model.summary())\r\n","    return model       \r\n","\r\n","model=define_model()\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","from keras.utils import np_utils\r\n","\r\n","trainLabels=np.array([1]* 7400 + [0]* 7400)\r\n","print(\"trainLabels:\",trainLabels)\r\n","testLabels=np.array([1] * 1850 + [0] * 1850)\r\n","\r\n","#train=np.array(train)\r\n","#print(train)\r\n","#print(\"pair:\", train.shape)\r\n","#print(train.shape)\r\n","\r\n","train_1=np.array(train_1)\r\n","train_2=np.array(train_2)\r\n","test_1=np.array(test_2)\r\n","test_2=np.array(test_1)\r\n","\r\n","\r\n","train_1.resize((14800,300,20,2),refcheck = False)\r\n","train_2.resize((14800,300,20,2),refcheck = False)\r\n","test_1.resize((3700,300,20,2),refcheck = False)\r\n","\r\n","test_2.resize((3700,300,20,2),refcheck = False)\r\n","\r\n","#train.reshape(100,30,2,2)\r\n","#test.reshape(3700,300,20,2)\r\n","#print(train.shape)\r\n","#print(test.shape)\r\n","\r\n","model.fit([train_1, train_2], trainLabels ,batch_size=64, epochs=10, shuffle= False)### Shuffle =true\r\n","\r\n","\r\n","print(\"Testing: \")\r\n","\r\n","accuracy=model.evaluate([test_1,test_2],testLabels)\r\n","print('Accuracy:', accuracy)\r\n","\r\n","\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","from sklearn import metrics\r\n","\r\n","\r\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report \r\n","\r\n","predictions = model.predict([test])\r\n","predictions =(predictions  > 0.5)\r\n","#y_pred = [int(val) for val in predictions]\r\n","#print(y_pred)\r\n","acc = accuracy_score(testLabels, predictions)\r\n","print(\"accuracy %.2f\", (acc * 100))\r\n","\r\n","cm=confusion_matrix(testLabels,predictions)\r\n","report=classification_report(testLabels,predictions)\r\n","print(\"cm\",cm)\r\n","print(\"report\",report)\r\n","\r\n","\r\n","\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","from sklearn import metrics\r\n","\r\n","#cm = metrics.confusion_matrix([test_1,test_2], predictions)\r\n","#print(cm)\r\n","\r\n","\r\n","print(\"Testing: \")\r\n","\r\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report \r\n","predictions = model.predict([test])\r\n","y_pred = [int(val) for val in predictions]\r\n","print(y_pred)\r\n","acc = accuracy_score(testLabels, y_pred)\r\n","print(\"accuracy %.2f\", (acc * 100))\r\n","\r\n","cm=confusion_matrix(testLabels,y_pred)\r\n","report=classification_report(testLabels,y_pred)\r\n","print(\"cm\",cm)\r\n","print(\"report\",report)\r\n","\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]}]}