{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copie de Untitled6.ipynb","provenance":[{"file_id":"13jO5GuDMbl4ZmH_b_wjNFBO4awTsNcd2","timestamp":1614024359811}],"authorship_tag":"ABX9TyO5316mKabkHFCcD2sLxt2o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"D90GGEuIQQRy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1614023951444,"user_tz":-60,"elapsed":13159,"user":{"displayName":"SSBSE Admin","photoUrl":"","userId":"11167642343971864398"}},"outputId":"a004bf8c-1670-41b1-8f70-3bb0272e8651"},"source":["#Importing packages\r\n","#import nltk\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","import re\r\n","import string\r\n","#from nltk import sent_tokenize, word_tokenize\r\n","#from nltk.corpus import stopwords\r\n","from nltk.stem.porter import PorterStemmer\r\n","import numpy as np\r\n","from tensorflow.keras import optimizers\r\n","from tensorflow.python.keras.optimizers import TFOptimizer\r\n","import numpy as np\r\n","from nltk.corpus import stopwords\r\n","import string\r\n","from pickle import load\r\n","from numpy import array\r\n","from keras.preprocessing.text import Tokenizer\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.utils.vis_utils import plot_model\r\n","from keras.models import Model\r\n","from keras.layers import Input\r\n","from keras.layers import Dense\r\n","from keras.layers import Flatten\r\n","from keras.layers import Dropout\r\n","from keras.layers import Embedding\r\n","from keras.layers.convolutional import Conv1D\r\n","from keras.layers.convolutional import Conv2D\r\n","from keras.layers.convolutional import Conv3D\r\n","from keras.layers.convolutional import MaxPooling2D\r\n","from keras.layers.convolutional import MaxPooling3D\r\n","from keras.layers.convolutional import MaxPooling1D\r\n","from keras.layers.normalization import BatchNormalization\r\n","from keras.layers.merge import concatenate\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","\r\n","def clean_doc(doc):\r\n","\ttokens = doc.split()\r\n","\ttable = str.maketrans('', '', string.punctuation)\r\n","\t#nltk.max_length=300\r\n","\ttokens = [w.translate(table) for w in tokens]\r\n","\ttokens = [word for word in tokens if word.isalpha()]\r\n","\tstop_words = list(set(stopwords.words('english')))\r\n","\tnewStopWords = ['java','com','org']\r\n","\tstop_words.extend(newStopWords)\r\n","\ttokens = [w for w in tokens if not w in stop_words]\r\n","\ttokens = [word for word in tokens if len(word) > 1]\r\n","\tps = PorterStemmer()\r\n","\ttokens=[ps.stem(word) for word in tokens]\r\n","\t#max_length(tokens)\r\n","\treturn tokens\r\n","\r\n","\r\n","def get_all_elements_in_list_of_lists(list):\r\n","    count = 0\r\n","    for element in list:\r\n","        count += len(element)\r\n","    return count\r\n","\r\n","import nltk\r\n","nltk.download('stopwords')\r\n","\r\n","import re\r\n","from gensim.models import Phrases\r\n","from gensim.models import Word2Vec\r\n","import gensim\r\n","import csv\r\n","labeldup=[]\r\n","################################################ TRAINDATA\r\n","\r\n","with open(\"/content/dp_train.csv\", \"r\") as f, open(\"/content/2.csv\", \"r\") as f1, open(\"/content/3.csv\", \"r\") as fnd1, open(\"/content/4.csv\", \"r\") as fnd2:     \r\n","        reader = csv.reader(f)\r\n","        reader1 = csv.reader(f1)\r\n","        reader2 = csv.reader(fnd1)\r\n","        reader3 = csv.reader(fnd2)\r\n","\r\n","        rownumber = 0    \r\n","\r\n","        traindata = []\r\n","\r\n","        \r\n","        for row, row1, row2, row3 in zip(reader, reader1, reader2, reader3):\r\n","\r\n","             for c in row :\r\n","\r\n","                 cleanrow= clean_doc(c)\r\n","             traindata.append(cleanrow)\r\n","\r\n","             for c1 in row1 :\r\n","                 cleanrow1= clean_doc(c1)    \r\n","             traindata.append(cleanrow1)\r\n","             \r\n","             for c2 in row2 :\r\n","                 cleanrow2= clean_doc(c2)            \r\n","             traindata.append(cleanrow2)\r\n","\r\n","             for c3 in row3 :\r\n","                 cleanrow3= clean_doc(c3)            \r\n","             traindata.append(cleanrow3)         \r\n","             \r\n","    \r\n"," \r\n","        model = gensim.models.Word2Vec(traindata, size=20, min_count=1,  sg=0) \r\n","\r\n","\r\n","with open(\"/content/dp_train.csv\", \"r\") as f, open(\"/content/2.csv\", \"r\") as f1, open(\"/content/3.csv\", \"r\") as fnd1, open(\"/content/4.csv\", \"r\") as fnd2:     \r\n","        reader = csv.reader(f)\r\n","        reader1 = csv.reader(f1)\r\n","        reader2 = csv.reader(fnd1)\r\n","        reader3 = csv.reader(fnd2)\r\n","\r\n","        rownumber = 0    \r\n","        pair_d=[]\r\n","        pair_nd=[]\r\n","        train=[]\r\n","        matrix_b1=[]\r\n","        matrix_b2=[]\r\n","        matrix_b3=[]\r\n","        matrix_b4=[]\r\n","\r\n","        traindata = []\r\n","        train_d1=[]\r\n","        train_d2=[]\r\n","        train_nd1=[]\r\n","        train_nd2=[]        \r\n","        len_token=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\r\n","        #f = open(\"follow2.txt\", 'w')     \r\n","        #Cleaning\r\n","        for row, row1, row2, row3 in zip(reader, reader1, reader2, reader3):\r\n","             \r\n","             for c in row :\r\n","                 cleanrow= clean_doc(c)\r\n","                 #print(cleanrow)\r\n","             for c1 in row1 :\r\n","                 cleanrow1= clean_doc(c1) \r\n","             for c2 in row2 :\r\n","                 cleanrow2= clean_doc(c2)            \r\n","             for c3 in row3 :\r\n","                 cleanrow3= clean_doc(c3)  \r\n","                 \r\n","################################## Duplicate Bug report 1\r\n","\r\n","             \r\n","             #f.write(\"Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                \r\n","                \r\n","             #f.write(str(cleanrow))\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","             \r\n","             \r\n","             matrix_b1=[] \r\n","             \r\n","             matrix_b1= list(matrix_b1)        \r\n","             for i in cleanrow :        \r\n","                 \r\n","                     matrix1_b= model.wv[i] \r\n","                     \r\n","                     matrix_b1.append(matrix1_b)\r\n","                     \r\n","                     \r\n","                     \r\n","                     \r\n","             #f.write(\"matrix_b1:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b1))\r\n","             \r\n","             #f.write(\"\\n\")\r\n","                 \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b1:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b1)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","             \r\n","             \r\n","             \r\n","###############################################################\r\n","             \r\n","     #Duplicate Bug report 2      \r\n","             #f.write(\"Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(cleanrow1))\r\n","             #f.write(\"\\n\")             \r\n","\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")                     \r\n","                     \r\n","             matrix_b2=[]         \r\n","             matrix_b2= list(matrix_b2)        \r\n","             for i in cleanrow1 :        \r\n","                 \r\n","                     matrix2_b= model.wv[i]                     \r\n","                     matrix_b2.append(matrix2_b)  \r\n","                     \r\n","             #f.write(\"matrix_b2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b2))\r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #print(matrix_b1)   \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b2)))  \r\n","             \r\n","             \r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b1)):\r\n","                 matrix_b1.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b2)):\r\n","                 matrix_b2.append(len_token)\r\n","             \r\n","            \r\n","\r\n","\r\n","\r\n","\r\n","             train_d1.append(matrix_b1)\r\n","             train_d2.append(matrix_b2)\r\n","       \r\n","                    \r\n","             rownumber = rownumber + 1\r\n","             print(\"train\",rownumber)\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(str(matrix_b2))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(train_d2))\r\n","             #f.write(\"\\n\")\r\n","\r\n","####################################################################################\r\n","             \r\n"," #Non Duplicate pairs \r\n","             \r\n","             \r\n","             #f.write(\"Non Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                          \r\n","             #f.write(str(cleanrow2))\r\n","             #f.write(\"\\n\")             \r\n","             \r\n","             \r\n","             matrix_b3=[] \r\n","             matrix_b3= list(matrix_b3)\r\n","             for i in cleanrow2 :\r\n","\r\n","                     matrix1_nb= model.wv[i]                        \r\n","                     matrix_b3.append(matrix1_nb)\r\n","                     \r\n","             #f.write(\"matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b3))\r\n","             \r\n","             #f.write(\"\\n\")\r\n"," \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b3)))\r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n"," \r\n","##################################################################\"\"\"\"\r\n","\r\n","                    \r\n","        # Non Duplicate Bug report 2 \r\n","\r\n","             #f.write(\"Non Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")   \r\n","             \r\n","             #f.write(str(cleanrow3))\r\n","             #f.write(\"\\n\")\r\n","                 \r\n","             matrix_b4=[]         \r\n","             matrix_b4= list(matrix_b4)      \r\n","             \r\n","             \r\n","             \r\n","             for i in cleanrow3 :        \r\n","                 \r\n","                     matrix2_nb= model.wv[i]                     \r\n","                     matrix_b4.append(matrix2_nb) \r\n","                     \r\n","                     \r\n","             for i in range(300 - len(matrix_b3)):\r\n","                 matrix_b3.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b4)):\r\n","                 matrix_b4.append(len_token)\r\n","             \r\n","                \r\n","\r\n","             train_nd1.append(matrix_b3)\r\n","             train_nd2.append(matrix_b4)             \r\n","                \r\n","                \r\n","                \r\n","             #f.write(\"matrix_b4\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b4))\r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #print(matrix_b1) \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b4\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b4)))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(train_nd2))\r\n","             #f.write(\"\\n\")\r\n","\r\n","             \r\n","             rownumber = rownumber + 1\r\n","             print(\"train\",rownumber)\r\n","        #f.close()  \r\n","\r\n","train_1 = train_d1 + train_nd1 #br1\r\n","train_2 = train_d2 + train_nd2  #br2\r\n","\r\n","################################################### TEST \"\"\"\"\"\"\r\n","\r\n","\r\n","with open(\"/content/5.csv\", \"r\") as f, open(\"/content/6.csv\", \"r\") as f1, open(\"/content/7.csv\", \"r\") as fnd1, open(\"/content/8.csv\", \"r\") as fnd2:     \r\n","        reader = csv.reader(f)\r\n","        reader1 = csv.reader(f1)\r\n","        reader2 = csv.reader(fnd1)\r\n","        reader3 = csv.reader(fnd2)\r\n","        rownumber = 0    \r\n","        test_d=[]\r\n","        b1=[]\r\n","        test_nd=[]\r\n","        b2=[]\r\n","        test=[]\r\n","        matrix_b1=[]\r\n","        matrix_b2=[]\r\n","        matrix_b3=[]\r\n","        matrix_b4=[]\r\n","        test_d1=[]\r\n","        test_d2=[]\r\n","        test_nd1=[]\r\n","        test_nd2=[]         \r\n","      \r\n","        traindata = []\r\n","        non_vocab= [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\r\n","        MAX_SEQUENCE_LENGTH =300\r\n","        #f = open(\"t2.txt\", 'w')\r\n","        for row, row1, row2, row3 in zip(reader, reader1, reader2, reader3):\r\n","             #g=open('dup_mat/'\"train\"+str(rownumber)+\".txt\",\"w\")\r\n","             for c in row :\r\n","                 cleanrow= clean_doc(c)\r\n","             for c1 in row1 :\r\n","                 cleanrow1= clean_doc(c1) \r\n","             for c2 in row2 :\r\n","                 cleanrow2= clean_doc(c2)            \r\n","             for c3 in row3 :\r\n","                 cleanrow3= clean_doc(c3)   \r\n"," \r\n","             #f.write(\"Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                   \r\n","                 \r\n","             #f.write(str(cleanrow))\r\n","             #f.write(\"\\n\")                  \r\n","\r\n","             #f.write(\"\\n\")\r\n","             matrix_b1=[]    \r\n","             matrix_b1= list(matrix_b1)    \r\n","             for i in cleanrow :\r\n","                 if i in model.wv.vocab:\r\n","                     matrix1_b= model.wv[i]                         \r\n","                     matrix_b1.append(matrix1_b) \r\n","                     \r\n","                 else:\r\n","                     matrix_b1.append(non_vocab) \r\n","                  \r\n","                     \r\n","             #f.write(\"matrix_b1:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b1))\r\n","                 \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b1:\")\r\n","             #f.write(str(len(matrix_b1)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","             \r\n","##########################################â™£\"\"             \r\n","             \r\n","#Duplicate Bug report 2 \r\n","             \r\n","\r\n","             #f.write(\" Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")   \r\n","\r\n","             #f.write(str(cleanrow1))\r\n","             #f.write(\"\\n\")              \r\n","\r\n","             #f.write(\"\\n\")                     \r\n","             \r\n","             \r\n","             \r\n","             \r\n","             matrix_b2=[]    \r\n","             matrix_b2= list(matrix_b2)        \r\n","             for i in cleanrow1 :\r\n","                 if i in model.wv.vocab:\r\n","                     #print(i)                    \r\n","                     matrix2_b= model.wv[i]                     \r\n","                     matrix_b2.append(matrix2_b) \r\n","                 else:\r\n","                     matrix_b2.append(non_vocab) \r\n"," \r\n","             #f.write(\"matrix_b2:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b2))\r\n","  \r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b1:\")\r\n","             #f.write(str(len(matrix_b2)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","\r\n","\r\n","\r\n","             for i in range(300 - len(matrix_b1)):\r\n","                 matrix_b1.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b2)):\r\n","                 matrix_b2.append(len_token)\r\n","             \r\n","\r\n","\r\n","             test_d1.append(matrix_b1)\r\n","             test_d2.append(matrix_b2)    \r\n","             \r\n","             #f.write(\"\\n\")\r\n","            # f.write(\"test_d:\") \r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(test_d))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")             \r\n","             \r\n","             \r\n","             \r\n","             \r\n","             #print(test_d)\r\n","             \r\n","             #f.write(\"Non Duplicate Bug report 1:\")\r\n","             #f.write(\"\\n\")                \r\n","             \r\n","             #f.write(str(cleanrow2))\r\n","\r\n","             #f.write(\"\\n\")\r\n","\r\n","             \r\n","             matrix_b3=[]    \r\n","             matrix_b3= list(matrix_b3)\r\n","             for i in cleanrow2 :\r\n","                 if i in model.wv.vocab:\r\n","                     matrix1_nb= model.wv[i]                        \r\n","                     matrix_b3.append(matrix1_nb)\r\n","                 else:\r\n","                     matrix_b3.append(non_vocab)\r\n","\r\n","             #f.write(\"matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b3))\r\n","  \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b3:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b3)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","\r\n","                  \r\n","    #Duplicate Bug report 2    \r\n","\r\n","\r\n","             #f.write(\"Non Duplicate Bug report 2:\")\r\n","             #f.write(\"\\n\")   \r\n","\r\n","\r\n","\r\n","             #f.write(str(cleanrow3))\r\n","             #f.write(\"\\n\") \r\n","\r\n","             #f.write(\"\\n\")\r\n","              \r\n","             matrix_b4=[]    \r\n","             matrix_b4= list(matrix_b4)        \r\n","             for i in cleanrow3 :\r\n","                 if i in model.wv.vocab:\r\n","                     #print(i)                    \r\n","                     matrix2_nb= model.wv[i]                     \r\n","                     matrix_b4.append(matrix2_nb) \r\n","                 else:\r\n","                     matrix_b4.append(non_vocab)\r\n","\r\n","             #f.write(\"matrix_b4:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(matrix_b4))\r\n","  \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"len matrix_b4:\")\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(len(matrix_b4)))\r\n","             \r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")\r\n","             \r\n","             for i in range(300 - len(matrix_b3)):\r\n","                 matrix_b3.append(len_token)\r\n","             \r\n","             \r\n","             for i in range(300 - len(matrix_b4)):\r\n","                 matrix_b4.append(len_token)\r\n","             \r\n","                \r\n","             #print(matrix_b2)   \r\n","\r\n","             test_nd1.append(matrix_b3)\r\n","             test_nd2.append(matrix_b4)    \r\n","             #print(pairx)\r\n","\r\n","             \r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"test_nd:\") \r\n","             #f.write(\"\\n\")\r\n","\r\n","             #f.write(\"\\n\")\r\n","             #f.write(str(test_nd))\r\n","             #f.write(\"\\n\")\r\n","             #f.write(\"\\n\")             \r\n","                          \r\n","             rownumber = rownumber + 1\r\n","             #f.close()         \r\n","             \r\n","test_1 = test_d1 + test_nd1\r\n","test_2 = test_d2 + test_nd2\r\n","      \r\n","\r\n","#train= np.stack([train_1,train_2],axis=0)\r\n","#test= np.stack([test_1,test_2],axis=0)\r\n","#m =np.stack([2,4],axis=-1)\r\n","#print(train.shape)\r\n","#print(test.shape)\r\n","train_1 =np.array(train_1)\r\n","#train_2 =np.array(train_2)\r\n","#test_1 =np.array(test_1)\r\n","#test2=np.array(test_2)\r\n","print(train_1.shape)\r\n","\r\n","\"\"\"\r\n","mat = np.empty((len(a),len(b)),dtype='object')\r\n","for i,aa in enumerate(a):\r\n","    for j,bb in enumerate(b): \r\n","        mat[i,j] = np.array([aa,bb],dtype='object')\r\n","\"\"\"\r\n","\r\n","#train_1  : train duplicate + train non dup : BR1\r\n","#train_2   :train  dup + train non dup : BR2 \r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","train 1\n","train 2\n","train 3\n","train 4\n","train 5\n","train 6\n","train 7\n","train 8\n","train 9\n","train 10\n","train 11\n","train 12\n","train 13\n","train 14\n","train 15\n","train 16\n","train 17\n","train 18\n","train 19\n","train 20\n","train 21\n","train 22\n","train 23\n","train 24\n","train 25\n","train 26\n","train 27\n","train 28\n","train 29\n","train 30\n","train 31\n","train 32\n","train 33\n","train 34\n","train 35\n","train 36\n","train 37\n","train 38\n","train 39\n","train 40\n","train 41\n","train 42\n","train 43\n","train 44\n","train 45\n","train 46\n","train 47\n","train 48\n","train 49\n","train 50\n","train 51\n","train 52\n","train 53\n","train 54\n","train 55\n","train 56\n","train 57\n","train 58\n","train 59\n","train 60\n","train 61\n","train 62\n","train 63\n","train 64\n","train 65\n","train 66\n","train 67\n","train 68\n","train 69\n","train 70\n","train 71\n","train 72\n","train 73\n","train 74\n","train 75\n","train 76\n","train 77\n","train 78\n","train 79\n","train 80\n","train 81\n","train 82\n","train 83\n","train 84\n","train 85\n","train 86\n","train 87\n","train 88\n","train 89\n","train 90\n","train 91\n","train 92\n","train 93\n","train 94\n","train 95\n","train 96\n","train 97\n","train 98\n","train 99\n","train 100\n","train 101\n","train 102\n","train 103\n","train 104\n","train 105\n","train 106\n","train 107\n","train 108\n","train 109\n","train 110\n","train 111\n","train 112\n","train 113\n","train 114\n","train 115\n","train 116\n","train 117\n","train 118\n","train 119\n","train 120\n","train 121\n","train 122\n","train 123\n","train 124\n","train 125\n","train 126\n","train 127\n","train 128\n","train 129\n","train 130\n","train 131\n","train 132\n","train 133\n","train 134\n","train 135\n","train 136\n","train 137\n","train 138\n","train 139\n","train 140\n","train 141\n","train 142\n","train 143\n","train 144\n","train 145\n","train 146\n","train 147\n","train 148\n","train 149\n","train 150\n","train 151\n","train 152\n","train 153\n","train 154\n","train 155\n","train 156\n","train 157\n","train 158\n","train 159\n","train 160\n","train 161\n","train 162\n","train 163\n","train 164\n","train 165\n","train 166\n","train 167\n","train 168\n","train 169\n","train 170\n","train 171\n","train 172\n","train 173\n","train 174\n","train 175\n","train 176\n","train 177\n","train 178\n","train 179\n","train 180\n","train 181\n","train 182\n","train 183\n","train 184\n","train 185\n","train 186\n","train 187\n","train 188\n","train 189\n","train 190\n","train 191\n","train 192\n","train 193\n","train 194\n","train 195\n","train 196\n","train 197\n","train 198\n","train 199\n","train 200\n","train 201\n","train 202\n","train 203\n","train 204\n","train 205\n","train 206\n","train 207\n","train 208\n","train 209\n","train 210\n","train 211\n","train 212\n","train 213\n","train 214\n","train 215\n","train 216\n","train 217\n","train 218\n","train 219\n","train 220\n","train 221\n","train 222\n","train 223\n","train 224\n","train 225\n","train 226\n","train 227\n","train 228\n","train 229\n","train 230\n","train 231\n","train 232\n","train 233\n","train 234\n","train 235\n","train 236\n","train 237\n","train 238\n","train 239\n","train 240\n","train 241\n","train 242\n","train 243\n","train 244\n","train 245\n","train 246\n","train 247\n","train 248\n","train 249\n","train 250\n","train 251\n","train 252\n","train 253\n","train 254\n","train 255\n","train 256\n","train 257\n","train 258\n","train 259\n","train 260\n","train 261\n","train 262\n","train 263\n","train 264\n","train 265\n","train 266\n","train 267\n","train 268\n","train 269\n","train 270\n","train 271\n","train 272\n","train 273\n","train 274\n","train 275\n","train 276\n","train 277\n","train 278\n","train 279\n","train 280\n","train 281\n","train 282\n","train 283\n","train 284\n","train 285\n","train 286\n","train 287\n","train 288\n","train 289\n","train 290\n","train 291\n","train 292\n","train 293\n","train 294\n","train 295\n","train 296\n","train 297\n","train 298\n","train 299\n","train 300\n","train 301\n","train 302\n","train 303\n","train 304\n","train 305\n","train 306\n","train 307\n","train 308\n","train 309\n","train 310\n","train 311\n","train 312\n","train 313\n","train 314\n","train 315\n","train 316\n","train 317\n","train 318\n","train 319\n","train 320\n","train 321\n","train 322\n","train 323\n","train 324\n","train 325\n","train 326\n","train 327\n","train 328\n","train 329\n","train 330\n","train 331\n","train 332\n","train 333\n","train 334\n","train 335\n","train 336\n","train 337\n","train 338\n","train 339\n","train 340\n","train 341\n","train 342\n","train 343\n","train 344\n","train 345\n","train 346\n","train 347\n","train 348\n","train 349\n","train 350\n","train 351\n","train 352\n","train 353\n","train 354\n","train 355\n","train 356\n","train 357\n","train 358\n","train 359\n","train 360\n","train 361\n","train 362\n","train 363\n","train 364\n","train 365\n","train 366\n","train 367\n","train 368\n","train 369\n","train 370\n","train 371\n","train 372\n","train 373\n","train 374\n","train 375\n","train 376\n","train 377\n","train 378\n","train 379\n","train 380\n","train 381\n","train 382\n","train 383\n","train 384\n","train 385\n","train 386\n","train 387\n","train 388\n","train 389\n","train 390\n","train 391\n","train 392\n","train 393\n","train 394\n","train 395\n","train 396\n","train 397\n","train 398\n","train 399\n","train 400\n","train 401\n","train 402\n","train 403\n","train 404\n","train 405\n","train 406\n","train 407\n","train 408\n","train 409\n","train 410\n","train 411\n","train 412\n","train 413\n","train 414\n","train 415\n","train 416\n","train 417\n","train 418\n","train 419\n","train 420\n","train 421\n","train 422\n","train 423\n","train 424\n","train 425\n","train 426\n","train 427\n","train 428\n","train 429\n","train 430\n","train 431\n","train 432\n","train 433\n","train 434\n","train 435\n","train 436\n","train 437\n","train 438\n","train 439\n","train 440\n","train 441\n","train 442\n","train 443\n","train 444\n","train 445\n","train 446\n","train 447\n","train 448\n","train 449\n","train 450\n","train 451\n","train 452\n","train 453\n","train 454\n","train 455\n","train 456\n","train 457\n","train 458\n","train 459\n","train 460\n","train 461\n","train 462\n","train 463\n","train 464\n","train 465\n","train 466\n","train 467\n","train 468\n","train 469\n","train 470\n","train 471\n","train 472\n","train 473\n","train 474\n","train 475\n","train 476\n","train 477\n","train 478\n","train 479\n","train 480\n","train 481\n","train 482\n","train 483\n","train 484\n","train 485\n","train 486\n","train 487\n","train 488\n","train 489\n","train 490\n","train 491\n","train 492\n","train 493\n","train 494\n","train 495\n","train 496\n","train 497\n","train 498\n","train 499\n","train 500\n","train 501\n","train 502\n","train 503\n","train 504\n","train 505\n","train 506\n","train 507\n","train 508\n","train 509\n","train 510\n","train 511\n","train 512\n","train 513\n","train 514\n","train 515\n","train 516\n","train 517\n","train 518\n","train 519\n","train 520\n","train 521\n","train 522\n","train 523\n","train 524\n","train 525\n","train 526\n","train 527\n","train 528\n","train 529\n","train 530\n","train 531\n","train 532\n","train 533\n","train 534\n","train 535\n","train 536\n","train 537\n","train 538\n","train 539\n","train 540\n","train 541\n","train 542\n","train 543\n","train 544\n","train 545\n","train 546\n","train 547\n","train 548\n","train 549\n","train 550\n","train 551\n","train 552\n","train 553\n","train 554\n","train 555\n","train 556\n","train 557\n","train 558\n","train 559\n","train 560\n","train 561\n","train 562\n","train 563\n","train 564\n","train 565\n","train 566\n","train 567\n","train 568\n","train 569\n","train 570\n","train 571\n","train 572\n","train 573\n","train 574\n","train 575\n","train 576\n","train 577\n","train 578\n","train 579\n","train 580\n","train 581\n","train 582\n","train 583\n","train 584\n","train 585\n","train 586\n","train 587\n","train 588\n","train 589\n","train 590\n","train 591\n","train 592\n","train 593\n","train 594\n","train 595\n","train 596\n","train 597\n","train 598\n","train 599\n","train 600\n","(600,)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:574: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nmat = np.empty((len(a),len(b)),dtype='object')\\nfor i,aa in enumerate(a):\\n    for j,bb in enumerate(b): \\n        mat[i,j] = np.array([aa,bb],dtype='object')\\n\""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"LN866EENXbZB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614023987244,"user_tz":-60,"elapsed":6722,"user":{"displayName":"SSBSE Admin","photoUrl":"","userId":"11167642343971864398"}},"outputId":"ae75ec54-443c-44bd-f883-2f7aeaf1ced0"},"source":["\"\"\"\r\n","train_1 = np.asarray(train_1)\r\n","train_2 = np.asarray(train_2)\r\n","test_1 = np.asarray(test_1)\r\n","test_2 = np.asarray(test_2)\r\n","\"\"\"\r\n","\r\n","\r\n","import tensorflow as tf\r\n","tf.keras.metrics.Precision( thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\r\n","tf.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\r\n","tf.keras.metrics.FalseNegatives( thresholds=None, name=None, dtype=None)\r\n","tf.keras.metrics.FalsePositives(thresholds=None, name=None, dtype=None)\r\n","tf.keras.metrics.TrueNegatives(thresholds=None, name=None, dtype=None)\r\n","tf.keras.metrics.TruePositives(thresholds=None, name=None, dtype=None)\r\n","#tf.keras.metrics.Accuracy(name='accuracy', dtype=None)\r\n","#tf.keras.metrics.Accuracy(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\r\n","import tensorflow as tf\r\n","import tensorflow \r\n","from keras import layers\r\n","from keras import Input\r\n","from tensorflow import keras\r\n","from keras.layers import Dense\r\n","from tensorflow.keras.layers import Reshape\r\n","# define the model\r\n","\r\n","import keras.backend as k\r\n","\r\n","\r\n","#train_1=tf.convert_to_tensor(train_1)\r\n","#train_2=np.asarray(train_2)\r\n","#test_1=np.asarray(test_1)\r\n","#test_2=np.asarray(test_2)\r\n","\r\n","#import tf.keras.layers.Reshape\r\n","def define_model():\r\n","\t# channel 1\r\n","    #inputs1 = Input(shape=(tt.shape)) \r\n","    inputs1 = Input(shape=(300,20,2)) \r\n","    #inputs2 = Input(shape=(300,20)) \r\n","    #inputs12=tf.keras.backend.stack(([inputs1,inputs2]),axis=-1) #(300,20,2) tf.keras.backend.stack(     x,     axis=0 ) \r\n","    #print(inputs1.shape)\r\n","    print(\"inputs1: \",inputs1.shape)\r\n","    conv1 = Conv2D(filters=100, kernel_size=(1,20), padding='valid', activation='relu', data_format='channels_last')(inputs1)\r\n","    #print(conv1)# \"(300,1,100)\"\r\n","    print(\"conv1:\",conv1.shape)\r\n","    x= layers.Reshape((300,100,1))(conv1)\r\n","    print(\"x:\",x.shape)\r\n","    conv11 = Conv2D(filters=200, kernel_size=(1,100), padding='valid', activation='relu')(x)\r\n","    print(\"conv11:\",conv11.shape)\r\n","    pool11 = MaxPooling2D(pool_size=(300, 1))(conv11)\r\n","    print(\"pool11:\",pool11.shape)\r\n","    flat11 = Flatten()(pool11)\r\n","    print(flat11.shape)\r\n","    # Branch12\r\n","    conv12 = Conv2D(filters=200, kernel_size=(2,100), padding='valid', activation='relu')(x)\r\n","    print(\"conv12:\",conv12.shape)\r\n","    pool12 = MaxPooling2D(pool_size=(299, 1))(conv12)\r\n","    print(\"pool12:\",pool12.shape)\r\n","    flat12 = Flatten()(pool12)\r\n","    # Branch13\r\n","    conv13 = Conv2D(filters=200, kernel_size=(3,100), padding='valid', activation='relu')(x)\r\n","    print(\"conv13:\",conv13.shape)\r\n","    pool13 = MaxPooling2D(pool_size=(298, 1))(conv13)\r\n","    print(\"pool13:\", pool13.shape)\r\n","    flat13 = Flatten()(pool13)\r\n","    # Branch21\r\n","    conv2 = Conv2D(filters=100, kernel_size=(2,20), padding='valid', activation='relu', data_format='channels_last')(inputs1)\r\n","    print(\"conv2: \", conv2.shape )\r\n","    x2 = layers.Reshape((299,100,1))(conv2)\r\n","    print(\"x2:\", x2.shape)\r\n","    conv21 = Conv2D(filters=200, kernel_size=(1,100), padding='valid', activation='relu')(x2)\r\n","    print(\"conv21 :\",conv21.shape)\r\n","    pool21 = MaxPooling2D(pool_size=(299, 1))(conv21)#o2-maxpooling\r\n","    print(\"pool21: \",pool21.shape)\r\n","    flat21 = Flatten()(pool21)\r\n","    #Branch22\r\n","    conv22 = Conv2D(filters=200, kernel_size=(2,100), padding='valid', activation='relu')(x2)\r\n","    print(\"conv22:\", conv22.shape)\r\n","    pool22 = MaxPooling2D(pool_size=(298, 1))(conv22)\r\n","    print(\"pool22:\",pool22.shape)\r\n","    flat22 = Flatten()(pool22)\r\n","    #Branch23\r\n","    conv23 = Conv2D(filters=200, kernel_size=(3,100), padding='valid', activation='relu')(x2)\r\n","    print(\"conv23:\",conv23.shape)\r\n","    pool23 = MaxPooling2D(pool_size=(297, 1))(conv23)\r\n","    print(\"pool23: \",pool23.shape)\r\n","    flat23 = Flatten()(pool23)\r\n","    #Branch31\r\n","    conv3 = Conv2D(filters=100, kernel_size=(3,20), padding='valid', activation='relu', data_format='channels_last')(inputs1)\r\n","    print(\"conv3\",conv3.shape)\r\n","    x3 = layers.Reshape((298,100,1))(conv3)\r\n","    print(\"x3\",x3.shape)\r\n","    conv31 = Conv2D(filters=200, kernel_size=(1,100), padding='valid', activation='relu')(x3)\r\n","    print(\"conv31: \",conv31.shape)\r\n","    pool31 = MaxPooling2D(pool_size=(298, 1))(conv31)\r\n","    print(\"pool31\",pool31.shape)\r\n","    flat31 = Flatten()(pool31)\r\n","    #Branch32\r\n","    conv32 = Conv2D(filters=200, kernel_size=(2,100), padding='valid', activation='relu')(x3)\r\n","    print(\"conv32: \",conv32.shape)\r\n","    pool32 = MaxPooling2D(pool_size=(297, 1))(conv32)\r\n","    print(\"pool32\",pool32.shape)\r\n","    flat32 = Flatten()(pool32)\r\n","    #Branch33\r\n","    conv33 = Conv2D(filters=200, kernel_size=(3,100), padding='valid', activation='relu')(x3)\r\n","    print(\"conv33: \",conv33.shape)\r\n","    pool33 = MaxPooling2D(pool_size=(296, 1))(conv33)\r\n","    print(\"pool33\",pool33.shape)\r\n","    flat33 = Flatten()(pool33)\r\n","    # merge 'May be merge pools then flatten\r\n","    merged = concatenate([flat11, flat12, flat13, flat21, flat22, flat23, flat31, flat32, flat33])\r\n","    print(\"merged: \",merged.shape)\r\n","    # interpretation\r\n","    dense1 = Dense(300, activation='relu')(merged)\r\n","    dense2 = Dense(100, activation='relu')(dense1)\r\n","    outputs = Dense(1, activation='sigmoid')(dense2)\r\n","    print(outputs.shape)\r\n","    model = Model(inputs=[inputs1], outputs=outputs) #think about this\r\n","    # compile\r\n","    model.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy'])\r\n","    #model.compile(optimizer='adam', loss='binary_crossentropy' , metrics=[tf.keras.metrics.Accuracy(),tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.FalseNegatives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(), tf.keras.metrics.TruePositives() ])\r\n","\r\n","    # summarize\r\n","    print(model.summary())\r\n","    return model       \r\n","\r\n","model=define_model()\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","#train=np.array(train)\r\n","#print(train)\r\n","#print(\"pair:\", train.shape)\r\n","#print(train.shape)\r\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["inputs1:  (None, 300, 20, 2)\n","conv1: (None, 300, 1, 100)\n","x: (None, 300, 100, 1)\n","conv11: (None, 300, 1, 200)\n","pool11: (None, 1, 1, 200)\n","(None, 200)\n","conv12: (None, 299, 1, 200)\n","pool12: (None, 1, 1, 200)\n","conv13: (None, 298, 1, 200)\n","pool13: (None, 1, 1, 200)\n","conv2:  (None, 299, 1, 100)\n","x2: (None, 299, 100, 1)\n","conv21 : (None, 299, 1, 200)\n","pool21:  (None, 1, 1, 200)\n","conv22: (None, 298, 1, 200)\n","pool22: (None, 1, 1, 200)\n","conv23: (None, 297, 1, 200)\n","pool23:  (None, 1, 1, 200)\n","conv3 (None, 298, 1, 100)\n","x3 (None, 298, 100, 1)\n","conv31:  (None, 298, 1, 200)\n","pool31 (None, 1, 1, 200)\n","conv32:  (None, 297, 1, 200)\n","pool32 (None, 1, 1, 200)\n","conv33:  (None, 296, 1, 200)\n","pool33 (None, 1, 1, 200)\n","merged:  (None, 1800)\n","(None, 1)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 300, 20, 2)] 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 300, 1, 100)  4100        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 299, 1, 100)  8100        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 298, 1, 100)  12100       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 300, 100, 1)  0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 299, 100, 1)  0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 298, 100, 1)  0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 300, 1, 200)  20200       reshape[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 299, 1, 200)  40200       reshape[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 298, 1, 200)  60200       reshape[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 299, 1, 200)  20200       reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 298, 1, 200)  40200       reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 297, 1, 200)  60200       reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 298, 1, 200)  20200       reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 297, 1, 200)  40200       reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 296, 1, 200)  60200       reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 1, 1, 200)    0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 200)          0           max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 200)          0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 200)          0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 200)          0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 200)          0           max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","flatten_5 (Flatten)             (None, 200)          0           max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","flatten_6 (Flatten)             (None, 200)          0           max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","flatten_7 (Flatten)             (None, 200)          0           max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","flatten_8 (Flatten)             (None, 200)          0           max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 1800)         0           flatten[0][0]                    \n","                                                                 flatten_1[0][0]                  \n","                                                                 flatten_2[0][0]                  \n","                                                                 flatten_3[0][0]                  \n","                                                                 flatten_4[0][0]                  \n","                                                                 flatten_5[0][0]                  \n","                                                                 flatten_6[0][0]                  \n","                                                                 flatten_7[0][0]                  \n","                                                                 flatten_8[0][0]                  \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 300)          540300      concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 100)          30100       dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n","==================================================================================================\n","Total params: 956,601\n","Trainable params: 956,601\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sJTfKlny9tu","executionInfo":{"status":"ok","timestamp":1614023995342,"user_tz":-60,"elapsed":1019,"user":{"displayName":"SSBSE Admin","photoUrl":"","userId":"11167642343971864398"}},"outputId":"3f4754b5-3b6f-43ad-f271-b5b8fe09cc5f"},"source":["train_1=np.array(train_1)\r\n","train_2=np.array(train_2)\r\n","train_1.resize((300,20),refcheck = False) \r\n","train_2.resize((300,20),refcheck = False) \r\n","train= np.stack([train_1, train_2], axis=-1)\r\n","test= train= np.stack([test_1, test_2], axis=-1)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n","/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order, subok=True)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"_EhFI3ZhXLfW","executionInfo":{"status":"error","timestamp":1614024000999,"user_tz":-60,"elapsed":756,"user":{"displayName":"SSBSE Admin","photoUrl":"","userId":"11167642343971864398"}},"outputId":"e5d0f17a-72af-42ec-a390-8cd562009035"},"source":["\r\n","from keras.utils import np_utils\r\n","\r\n","trainLabels=np.array([1]* 300 + [0]*300)\r\n","#print(\"trainLabels:\",trainLabels)\r\n","testLabels=np.array([1] * 300 + [0] * 300)\r\n","\r\n","\r\n","\r\n","#train_1= tf.ragged.constant(train_1)\r\n","#train_1= np.array(train_1)\r\n","#train_2= np.array(train_2)\r\n","\r\n","#train_2= tf.ragged.constant(train_2)\r\n","#train_2=tf.convert_to_tensor(train_2)\r\n","\r\n","#trainLabels= np.asarray(trainLabels).astype(np.float32)\r\n","#test_1= np.asarray(test_1)\r\n","#test_2= np.asarray(test_2)\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","model.fit(train, trainLabels ,batch_size=64, epochs=3, shuffle= True)\r\n","\r\n","\r\n","print(\"Testing: \")\r\n","\r\n","accuracy=model.evaluate([test],testLabels)\r\n","print('Accuracy:', accuracy)\r\n","\r\n","\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","from sklearn import metrics\r\n","\r\n","\r\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report \r\n","\r\n","predictions = model.predict([train_1,train_2])\r\n","predictions =(predictions  > 0.5)\r\n","#y_pred = [int(val) for val in predictions]\r\n","#print(y_pred)\r\n","acc = accuracy_score(trainLabels, predictions)\r\n","print(\"accuracy %.2f\", (acc * 100))\r\n","\r\n","cm=confusion_matrix(trainLabels,predictions)\r\n","report=classification_report(trainLabels,predictions)\r\n","print(\"cm\",cm)\r\n","print(\"report\",report)\r\n","\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","from sklearn import metrics\r\n","\r\n","#cm = metrics.confusion_matrix([test_1,test_2], predictions)\r\n","#print(cm)\r\n","\r\n","\r\n","print(\"Testing: \")\r\n","\r\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report \r\n","predictions = model.predict([test_1,test_2])\r\n","y_pred = [int(val) for val in predictions]\r\n","print(y_pred)\r\n","acc = accuracy_score(testLabels, y_pred)\r\n","print(\"accuracy %.2f\", (acc * 100))\r\n","\r\n","cm=confusion_matrix(testLabels,y_pred)\r\n","report=classification_report(testLabels,y_pred)\r\n","print(\"cm\",cm)\r\n","print(\"report\",report)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7bba33b2382c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabels\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                **kwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    265\u001b[0m         sample_weights, sample_weight_modes)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."]}]}]}